{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# Sentiment Analysis Benchmarks\n",
    "\n",
    "This notebook contains benchmarks for selecting the best sentiment analysis solution to be included into the framework proposed in my dissertation. I am comparing three candidates:\n",
    "\n",
    "- TextBlob - basic lexicon-and-rule-based analyzer \n",
    "- TextBlob - pre-trained Naive Bayes classifier\n",
    "- VADER - lexicon-based analyzer desinged for social network posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:15:27.746767199Z",
     "start_time": "2023-08-09T14:15:27.706060871Z"
    },
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "import pandas as pd\n",
    "from sklearn.metrics import f1_score\n",
    "from textblob import TextBlob\n",
    "from textblob.en.sentiments import NaiveBayesAnalyzer\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "A small portion of the [Twitter Sentiment Dataset](https://www.kaggle.com/datasets/saurabhshahane/twitter-sentiment-dataset) will be used as ground truth for evaluation. This dataset contains tweets related to Indian politics. Each tweet is labeled as positive (1), negative(-1) or neutral(0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:12:43.717017058Z",
     "start_time": "2023-08-09T14:12:43.324411733Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...        -1\n",
       "1  talk all the nonsense and continue all the dra...         0\n",
       "2  what did just say vote for modi  welcome bjp t...         1\n",
       "3  asking his supporters prefix chowkidar their n...         1\n",
       "4  answer who among these the most powerful world...         1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv('../datasets/twitter_benchmark.csv').dropna()[:10000]\n",
    "tweets['category'] = tweets['category'].astype(int)\n",
    "tweets.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "All sentiment analysis methods under consideration return a continous polarity value ranging from -1 to 1. The following function transforms this continuous value into a label matching the evaluation dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:12:46.152175446Z",
     "start_time": "2023-08-09T14:12:46.136251175Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "DISCRETIZATION_BOUNDARY = 0.05\n",
    "\n",
    "def discretize_polarity(sent: float) -> int:\n",
    "    if sent < -DISCRETIZATION_BOUNDARY:\n",
    "        return -1\n",
    "    elif sent > DISCRETIZATION_BOUNDARY:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "Now we evaluate all 3 methods. Our metric of choice is `f1_score`.\n",
    "\n",
    "## TextBlob - lexicon based"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:12:50.999617157Z",
     "start_time": "2023-08-09T14:12:49.201610121Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.300000\n",
       "1    0.000000\n",
       "2    0.483333\n",
       "3    0.150000\n",
       "4    0.400000\n",
       "Name: clean_text, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments = tweets['clean_text'].apply(lambda t: TextBlob(t).sentiment.polarity)\n",
    "sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:13:03.697625421Z",
     "start_time": "2023-08-09T14:13:03.692989698Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -1\n",
       "1    0\n",
       "2    1\n",
       "3    1\n",
       "4    1\n",
       "Name: clean_text, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "sentiments = sentiments.apply(discretize_polarity)\n",
    "sentiments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:13:07.761401331Z",
     "start_time": "2023-08-09T14:13:07.752809682Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.93193707680778"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(tweets['category'], sentiments, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## VADER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:14:05.392924511Z",
     "start_time": "2023-08-09T14:14:04.482378217Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.5267\n",
       "1   -0.4019\n",
       "2    0.7096\n",
       "3   -0.0713\n",
       "4    0.4754\n",
       "Name: clean_text, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "vader_sentiment = tweets['clean_text'].apply(lambda t: analyzer.polarity_scores(t)['compound'])\n",
    "vader_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:14:31.399067507Z",
     "start_time": "2023-08-09T14:14:31.357807419Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1   -1\n",
       "2    1\n",
       "3   -1\n",
       "4    1\n",
       "Name: clean_text, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vader_sentiment = vader_sentiment.apply(discretize_polarity)\n",
    "vader_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:14:42.387901584Z",
     "start_time": "2023-08-09T14:14:42.346485020Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5622663754024169"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "f1_score(tweets['category'], vader_sentiment, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Naive Bayes\n",
    "\n",
    "The Naive Bayes sentiment returns the probability of a given tweet being positive (and a complementary probability of the tweet being negative). Before we can apply the discretization function we first transform this probability into \"polarity\" value from the expected `[-1; 1]` interval. We simply multiply the probability by 2 and subtract 1 from the result.\n",
    "\n",
    "Some `nltk` datasets are required to make the classifier work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:20:04.345556472Z",
     "start_time": "2023-08-09T14:20:00.125939442Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package movie_reviews to\n",
      "[nltk_data]     /home/milos/nltk_data...\n",
      "[nltk_data]   Package movie_reviews is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/milos/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.512373\n",
       "1   -0.591206\n",
       "2    0.782222\n",
       "3   -0.451511\n",
       "4    0.858200\n",
       "Name: clean_text, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('movie_reviews')\n",
    "nltk.download('punkt')\n",
    "nb = NaiveBayesAnalyzer()\n",
    "nb_sentiment = tweets['clean_text'].apply(lambda t: nb.analyze(t)[1] * 2 - 1)\n",
    "nb_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:20:09.296140921Z",
     "start_time": "2023-08-09T14:20:09.255612317Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1\n",
       "1   -1\n",
       "2    1\n",
       "3   -1\n",
       "4    1\n",
       "Name: clean_text, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nb_sentiment = nb_sentiment.apply(discretize_polarity)\n",
    "nb_sentiment.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-09T14:20:11.214559095Z",
     "start_time": "2023-08-09T14:20:11.204504880Z"
    },
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.34057464628325873"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1_score(tweets['category'], nb_sentiment, average='weighted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Conclusion\n",
    "\n",
    "We see that the TextBlob analyzer based on a sentiment lexicon plus several additional rules provides the best `f1_score`. It was therefore included into the proposed frameworks as the sentiment analysis solution."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
